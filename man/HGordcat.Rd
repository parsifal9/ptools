\name{HGordcat}

\alias{HGordcat}

\title{ GeneRave ordered categories classification}

\description{

Fits odds continuation ratio model for ordered categorical data - with sparsity prior

\deqn{logit \left(\frac{Pr(\mbox{class k})}%
{Pr(\mbox{less than or equal to class k})}\right) =%
\theta(k) + \beta'x}{%
logit\{Pr(class k)/Pr(less than or equal to class k)\} = theta(k) + beta'x}
for \eqn{1 < k \leq C}{1 < k \le C}.

Does simultaneous variable selection and parameter estimation. Can handle the
case of less observations than variables as well as the case of  many more
variables than observations.
}

\usage{
HGordcat(x, y, weights = rep(1, nrow(x)), sparsity.prior="NG", bbess=1e7, kbess=0)
}

\arguments{
	\item{x}{ real matrix with n rows (samples) and p columns (variables or genes)  }
	\item{y}{ real n by 1 vector of response values }
	\item{weights}{ real n by 1 vector of observation weights, default to 1 }
	\item{sparsity.prior}{one of "NG", "NEG", "DEG", "SCAD", or "R"  }
	\item{bbess}{real number in the range [0,1e7]}
	\item{kbess}{real number in the range [0,1]. The value for the SCAD prior can
  be bigger than one, see below.}
}

\details{
This function recasts and solves the problem internally as a logistic
regression. An intercept term is not forced into the model. Note that the
theta parameters are not subject to the prior. They are forced into the model.

The sparsity priors implemented are
\describe{
	\item{NG}{ the Normal Gamma prior with gamma scale and shape parameters
		\code{bbess} and \code{kbess} respectively. This default prior appears
		to work well in practise.
	}
	\item{NEG}{ the normal exponential gamma prior with gamma scale and shape
		parameters \code{bbess^-2} and \code{kbess} respectively.
		Griffin and Brown (2005)
	}
	\item{DEG}{ the double exponential gamma prior with gamma scale and shape
		parameters \code{bbess} and \code{kbess} respectively,
		Cawley and Talbot (2006). A special case of the NG prior
	}
	\item{SCAD}{ the SCAD prior (Fan and Li (2001)). The \code{a} and
		\code{lambda} parameters defined by Fan and Li are \code{bbess} and
		\code{kbess} respectively. The values \code{bbess = 3.7} and
		\code{kbess = 2} are Fan and Li's defaults.
	}
	\item{R}{the \dQuote{ridge} prior - proportional to exp(-bbess*beta'beta),
		\code{kbess} is ignored. Does not produce sparse models but may
		sometimes be useful for initial value generation
	}
}

	Note: the default values for \code{bbess} and \code{kbess} assume the
	\dQuote{NG} prior. These values should be specifically set for the other
	priors.
}

\value{ An object of class HGordcat which is a list with components

\item{beta}{ p by 1 vector of beta parameter estimates   }

 \item{S}{p by 1 logical vector with value true if variable selected i.e
  the corresponding beta is nonzero  }

 \item{P}{n by C matrix of fitted probabilities  }

 \item{varids}{ identifiers of variables selected }

 \item{theta}{ C-1 by 1 vector of fitted theta parameters  }

 \item{class}{n by 1 vector of fitted class labels  }

}

\references{
McCullagh(1980), Regression models for ordinal data (with discussion)
JRSS B 42, 109-142

Fan, J. and Li, R. (2001) Variable selection via penalized likelihood.
Journal of American Statistical Association, 96,1348-1360.

Figueiredo, M. (2003) Adaptive sparseness for supervised learning, IEEE
Transactions on Pattern Analysis and Machine Intelligence - PAMI, vol. 25,
no. 9 pp. 1150-1159

Kiiveri, H.T., A Bayesian approach to variable selection when the number of
variables is very large. In: Science and Statistics: A festschrift for Terry
Speed. IMS Lecture Notes - Monograph Series, Volume TBD (40 or 41).

Kiiveri, H.T. (2008). A general approach to simultaneous model fitting and variable elimination
in response models for biological data with many more variables than observations.
BMC Bioinformatics 2008, 9:195 (15 Apr 2008). Available at
\url{http://www.biomedcentral.com/1471-2105/9/195}

Griffin, J. E., and Brown, P. J. (2005). Alternative prior distributions
for variable selection with very many more variables than observations.
Technical report available at
\url{http://www2.warwick.ac.uk/fac/sci/statistics/crism/research/2005/paper05-10/05-10w.pdf}

Cawley, G., and Talbot, N.,(2006)
Gene selection in cancer classification using sparse logistic
regression with Bayesian regularization
Bioinformatics 22,19,2348-2355.

}

\author{Harri Kiiveri }

\note{
The maximum size matrix for inversion in the algorithm is min((G - 1) * n, p)
where G is the number of ordered categories. Missing values are not allowed.
}

\seealso{
\code{\link{HGglm}},
\code{\link{HGordcat}},
\code{\link{HGmultc}},
\code{\link{HGgaussian}},
\code{\link{HGcoxreg}},
\code{\link{HGsurv}},
\code{\link{DeleteRepeat}}
\code{\link{xvalidate}}
}

\examples{
# EXAMPLE - data not generated by model but still works

x <- matrix(rnorm(200 * 200), nrow = 200)
p <- matrix(0, nrow = 200, ncol = 3)

vec <- quantile(x[, 1], probs = c(0, 1/3, 2/3, 1))
vec[1] <- vec[1] - 0.1
vec[4] <- vec[4] + 0.1

y <- as.numeric(cut(x[, 1], vec))

res <- HGordcat(x, y)

#display chosen variables
res$varids
res$theta

# display parameter estimates
res$beta[res$S]

# display misclassification matrix
table(y, res$class)

#display fitted probs
round(res$P, 2)
}

\keyword{ models }

\keyword{ classif }

